[package_management]
manager = "uv"

[runtime]
auto_instantiate = false
output_max_bytes = 8000000
watcher_on_save = "lazy"
reactive_tests = true
default_csv_encoding = "utf-8"
std_stream_max_bytes = 1000000
on_cell_change = "autorun"
default_sql_output = "auto"
auto_reload = "autorun"

[mcp]
presets = ["marimo", "context7"]

[mcp.mcpServers]

[snippets]
custom_paths = []
include_default_snippets = true

[language_servers.pylsp]
enable_mypy = true
enable_pyflakes = false
enable_pylint = false
enabled = true
enable_ruff = true
enable_pydocstyle = false
enable_flake8 = false

[display]
cell_output = "below"
dataframes = "rich"
code_editor_font_size = 14
default_table_page_size = 10
reference_highlighting = true
default_table_max_columns = 50
theme = "dark"
default_width = "medium"

[keymap]
preset = "default"

[keymap.overrides]

[completion]
copilot = "custom"
signature_hint_on_typing = false
activate_on_typing = true

[formatting]
line_length = 88

[save]
autosave = "after_delay"
format_on_save = true
autosave_delay = 1000

[diagnostics]
sql_linter = true

[server]
follow_symlink = false
browser = "never"

[ai]
inline_tooltip = true

[ai.models]
chat_model = "lmstudio/openai/gpt-oss-20b"
edit_model = "lmstudio/openai/gpt-oss-20b"
autocomplete_model = "lmstudio/openai/gpt-oss-20b"
displayed_models = ["lmstudio/openai/gpt-oss-20b"]
custom_models = ["lmstudio/openai/gpt-oss-20b"]

[ai.custom_providers.lmstudio]
base_url = "http://host.docker.internal:11434/v1"
